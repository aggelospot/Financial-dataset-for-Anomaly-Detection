{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (Numeric columns only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop na:  (20140, 32)\n",
      "df columns at start  Index(['Unnamed: 0', 'bankruptcy_date_1', 'label', 'bankruptcy_date_2',\n",
      "       'filing_date', 'datadate', 'bankruptcy_date_3', 'opinion_text',\n",
      "       'item_7', 'bankruptcy_prediction_split', 'cik', 'company',\n",
      "       'period_of_report', 'cik_year', 'qualified', 'gc_list', 'can_label',\n",
      "       'filename', 'gvkey', 'CashAndCashEquivalentsAtCarryingValue',\n",
      "       'IncomeTaxExpenseBenefit', 'StockholdersEquity', 'Assets',\n",
      "       'LiabilitiesAndStockholdersEquity', 'EntityPublicFloat',\n",
      "       'NetIncomeLoss', 'NetCashProvidedByUsedInFinancingActivities',\n",
      "       'NetCashProvidedByUsedInInvestingActivities',\n",
      "       'NetCashProvidedByUsedInOperatingActivities', 'EarningsPerShareBasic',\n",
      "       'RetainedEarningsAccumulatedDeficit', 'EarningsPerShareDiluted'],\n",
      "      dtype='object')\n",
      "cols remaining:  Index(['Unnamed: 0', 'label', 'CashAndCashEquivalentsAtCarryingValue',\n",
      "       'IncomeTaxExpenseBenefit', 'StockholdersEquity', 'Assets',\n",
      "       'LiabilitiesAndStockholdersEquity', 'EntityPublicFloat',\n",
      "       'NetIncomeLoss', 'NetCashProvidedByUsedInFinancingActivities',\n",
      "       'NetCashProvidedByUsedInInvestingActivities',\n",
      "       'NetCashProvidedByUsedInOperatingActivities', 'EarningsPerShareBasic',\n",
      "       'RetainedEarningsAccumulatedDeficit', 'EarningsPerShareDiluted'],\n",
      "      dtype='object')\n",
      "???  0      2\n",
      "1      3\n",
      "2      4\n",
      "3      5\n",
      "4      6\n",
      "5      7\n",
      "6     15\n",
      "7     16\n",
      "8     17\n",
      "9     18\n",
      "10    19\n",
      "11    27\n",
      "12    30\n",
      "13    31\n",
      "14    32\n",
      "Name: Unnamed: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../outputs/processed_dataset.csv\")\n",
    "print(\"before drop na: \", df.shape)\n",
    "print(\"df columns at start \", df.columns)\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = [\n",
    "    'bankruptcy_prediction_split', \n",
    "    'filename',\n",
    "    'bankruptcy_date_1',\n",
    "    'bankruptcy_date_2',\n",
    "    'bankruptcy_date_3',\n",
    "    'period_of_report',\n",
    "    'can_label',\n",
    "    'qualified',\n",
    "    'filing_date',\n",
    "    'cik_year',\n",
    "    'opinion_text', \n",
    "    'item_7',\n",
    "    'gvkey', \n",
    "    'datadate',\n",
    "    'cik',\n",
    "    'company',\n",
    "    'gc_list'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "print(\"cols remaining: \", df.columns)\n",
    "print(\"??? \", df['Unnamed: 0'].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be used for training:  Index(['Unnamed: 0', 'CashAndCashEquivalentsAtCarryingValue',\n",
      "       'IncomeTaxExpenseBenefit', 'StockholdersEquity', 'Assets',\n",
      "       'LiabilitiesAndStockholdersEquity', 'EntityPublicFloat',\n",
      "       'NetIncomeLoss', 'NetCashProvidedByUsedInFinancingActivities',\n",
      "       'NetCashProvidedByUsedInInvestingActivities',\n",
      "       'NetCashProvidedByUsedInOperatingActivities', 'EarningsPerShareBasic',\n",
      "       'RetainedEarningsAccumulatedDeficit', 'EarningsPerShareDiluted'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.9220456802383317\n",
      "Confusion Matrix:\n",
      "[[3704  309]\n",
      " [   5   10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      4013\n",
      "           1       0.03      0.67      0.06        15\n",
      "\n",
      "    accuracy                           0.92      4028\n",
      "   macro avg       0.51      0.79      0.51      4028\n",
      "weighted avg       1.00      0.92      0.96      4028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features (X) and target (y)\n",
    "#    - Select all numeric columns except 'label' as features \n",
    "y = df['label'].astype(int)  # Ensure it's numeric (0 or 1)\n",
    "X = df.select_dtypes(include=['float', 'int']).drop(columns=['label'], errors='ignore')\n",
    "print(\"Columns to be used for training: \", X.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Dealing with class imbalance: \n",
    "#   - Create SMOTE instance\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Fit SMOTE on the training data to oversample the minority class\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and fit the LR model\n",
    "# logreg = LogisticRegression(class_weight=\"balanced\", max_iter=50000)\n",
    "# logreg.fit(X_train, y_train)\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 6. Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# 7. Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop na:  (20140, 32)\n",
      "Label frequency for label (before drop): 76 / 20140\n",
      "Number of NaNs in 'item_7': 129\n",
      "Number of empty strings in 'item_7': 0\n",
      "shape after drop:  (20011, 19)\n",
      "Label frequency for label: 76 / 20011\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../outputs/processed_dataset.csv\")\n",
    "print(\"before drop na: \", df.shape)\n",
    "label_frequency_date_1 = df[\"label\"].sum()\n",
    "cols_to_drop = ['bankruptcy_prediction_split', 'filename', 'period_of_report', 'gvkey', 'datadate', 'can_label', 'qualified', 'bankruptcy_date_1', 'bankruptcy_date_2', 'bankruptcy_date_3', 'filing_date', 'cik_year', 'opinion_text'] \n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "print(f\"Label frequency for label (before drop): {label_frequency_date_1} / {len(df)}\")\n",
    "\n",
    "print(\"Number of NaNs in 'item_7':\", df['item_7'].isna().sum())\n",
    "print(\"Number of empty strings in 'item_7':\", (df['item_7'] == \"\").sum())\n",
    "# df = df.dropna(subset=['item_7'])\n",
    "df.dropna(inplace=True)\n",
    "print(\"shape after drop: \", df.shape)\n",
    "label_frequency_date_1 = df[\"label\"].sum()\n",
    "print(f\"Label frequency for label: {label_frequency_date_1} / {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Numeric Cols + item_7 text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Shape:  (20140, 19)\n",
      "After dropping NAs from item_7:  (20011, 19)\n",
      "Accuracy: 0.9647764176867349\n",
      "Confusion Matrix:\n",
      " [[3852  136]\n",
      " [   5   10]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3988\n",
      "           1       0.07      0.67      0.12        15\n",
      "\n",
      "    accuracy                           0.96      4003\n",
      "   macro avg       0.53      0.82      0.55      4003\n",
      "weighted avg       1.00      0.96      0.98      4003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Dataset\n",
    "df = pd.read_csv(\"../outputs/processed_dataset.csv\")\n",
    "\n",
    "# Drop Columns Not Needed\n",
    "cols_to_drop = ['bankruptcy_prediction_split', 'filename', 'period_of_report', 'gvkey', 'datadate', 'can_label', 'qualified', 'bankruptcy_date_1', 'bankruptcy_date_2', 'bankruptcy_date_3', 'filing_date', 'cik_year', 'opinion_text'] \n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Drop rows where item_7 is NA\n",
    "print(\"Starting Shape: \", df.shape)\n",
    "df = df.dropna(subset=['item_7'])\n",
    "print(\"After dropping NAs from item_7: \", df.shape)\n",
    "\n",
    "# Separate Target\n",
    "y = df['label'].astype(int)\n",
    "\n",
    "# Identify Numeric and Text Columns\n",
    "#    for now i use \"item_7\" as the single text column, and the previous numeric cols are kept the same \n",
    "numeric_cols = df.select_dtypes(include=['int', 'float']).drop(columns=['label'], errors='ignore').columns\n",
    "text_col = 'item_7'  # The management discussion column\n",
    "\n",
    "# Train-Test Split\n",
    "# TODO: use 'bankruptcy prediction column' \n",
    "# - Compare that column with the old test set to make sure we havent lost too many rows.\n",
    "# - Visualize which years were mostly dropped in the original dataset  (percentage of dropped columns PER YEAR)\n",
    "# - Repeat for the labels\n",
    "# - Find some data points that were dropped and check the manually (mostly from the most recent years) (email)\n",
    "# - In the email include some examples with random datapoints. \n",
    "# - Add the auditor opinion \n",
    "# - USE METRICS: Avg Precision + recall at 100, ROC Curve \n",
    "\n",
    "# Notes: In the original ECL XGBoost was used \n",
    "# Future: Different models for each modality, different models for the text columns. \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build a ColumnTransformer\n",
    "#    TF-IDF Vectorizer for the \"item_7\" text, StandardScaler for the numeric cols\n",
    "## TODO: Remove stopwords\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text_tfidf\", TfidfVectorizer(max_features=5000), text_col),\n",
    "        (\"num\", StandardScaler(), numeric_cols)  # scale numeric features\n",
    "    ],\n",
    "    remainder='drop'  # drop any columns not specified above\n",
    ")\n",
    "\n",
    "# Create a Pipeline that combines:\n",
    "#    - Preprocessing (TF-IDF, StandardScaler)\n",
    "#    - SMOTE (oversampling)\n",
    "#    - LogisticRegression (classification)\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit the Pipeline on the Training Data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the Test Set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate Results\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
